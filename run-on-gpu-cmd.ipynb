{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'jieba'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-71874e60dc26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mjieba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'jieba'"
     ]
    }
   ],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jun 13 11:51:50 2018       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 384.111                Driver Version: 384.111                   |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:05:00.0 Off |                  N/A |\r\n",
      "| 29%   57C    P2    66W / 250W |   1792MiB / 11170MiB |     24%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:09:00.0 Off |                  N/A |\r\n",
      "|  0%   48C    P8    13W / 250W |     10MiB / 11172MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0     28443      C   /opt/anaconda3/bin/python                    875MiB |\r\n",
      "|    0     31849      C   python                                       907MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jun 13 14:19:38 2018       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 384.111                Driver Version: 384.111                   |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:05:00.0 Off |                  N/A |\r\n",
      "| 38%   60C    P2    66W / 250W |   1902MiB / 11170MiB |     24%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:09:00.0 Off |                  N/A |\r\n",
      "|  0%   49C    P8    13W / 250W |     10MiB / 11172MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0     28443      C   /opt/anaconda3/bin/python                    875MiB |\r\n",
      "|    0     31849      C   python                                      1017MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/notebook/jupyterhub/notebook_dirs/chenyy/QA\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/notebook/jupyterhub/notebook_dirs/chenyy/QA\r\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "babi_main.py:199: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
      "  init.uniform(self.word_embedding.state_dict()['weight'], a=-(3**0.5), b=3**0.5)\n",
      "babi_main.py:156: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "  if 'weight' in name: init.xavier_normal(param)\n",
      "babi_main.py:31: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "  init.xavier_normal(self.Wr.state_dict()['weight'])\n",
      "babi_main.py:33: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "  init.xavier_normal(self.Ur.state_dict()['weight'])\n",
      "babi_main.py:35: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "  init.xavier_normal(self.W.state_dict()['weight'])\n",
      "babi_main.py:37: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "  init.xavier_normal(self.U.state_dict()['weight'])\n",
      "babi_main.py:85: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "  init.xavier_normal(self.z1.state_dict()['weight'])\n",
      "babi_main.py:86: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "  init.xavier_normal(self.z2.state_dict()['weight'])\n",
      "babi_main.py:87: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "  init.xavier_normal(self.next_mem.state_dict()['weight'])\n",
      "babi_main.py:184: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "  init.xavier_normal(self.z.state_dict()['weight'])\n",
      "babi_main.py:113: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  G = F.softmax(G)\n",
      "babi_main.py:244: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = F.softmax(output)\n",
      "babi_main.py:289: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  print(f'[Task {task_id}, Epoch {epoch}] [Training] loss : {loss.data[0]: {10}.{8}}, acc : {total_acc / cnt: {5}.{4}}, batch_idx : {batch_idx}')\n",
      "[Task 1, Epoch 0] [Training] loss :  310.42636, acc :   0.0, batch_idx : 0\n",
      "[Task 1, Epoch 0] [Training] loss :  189.35339, acc :  0.1648, batch_idx : 20\n",
      "[Task 1, Epoch 0] [Training] loss :  168.42227, acc :  0.2266, batch_idx : 40\n",
      "[Task 1, Epoch 0] [Training] loss :  147.74544, acc :  0.3143, batch_idx : 60\n",
      "[Task 1, Epoch 0] [Training] loss :  137.83443, acc :  0.3699, batch_idx : 80\n",
      "contexts: torch.Size([100, 10, 8])\n",
      "contexts: torch.Size([100, 10, 8])\n",
      "contexts: torch.Size([100, 10, 8])\n",
      "contexts: torch.Size([100, 10, 8])\n",
      "contexts: torch.Size([100, 10, 8])\n",
      "contexts: torch.Size([100, 10, 8])\n",
      "contexts: torch.Size([100, 10, 8])\n",
      "contexts: torch.Size([100, 10, 8])\n",
      "contexts: torch.Size([100, 10, 8])\n",
      "contexts: torch.Size([100, 10, 8])\n",
      "[Run 0, Task 1, Epoch 0] [Validate] Accuracy :  0.657\n",
      "[Task 1, Epoch 1] [Training] loss :  106.43082, acc :  0.66, batch_idx : 0\n",
      "[Task 1, Epoch 1] [Training] loss :  45.512787, acc :  0.7871, batch_idx : 20\n",
      "[Task 1, Epoch 1] [Training] loss :  18.969101, acc :  0.8739, batch_idx : 40\n",
      "[Task 1, Epoch 1] [Training] loss :  9.9852743, acc :  0.9121, batch_idx : 60\n",
      "[Task 1, Epoch 1] [Training] loss :  3.6563289, acc :  0.9332, batch_idx : 80\n",
      "contexts: torch.Size([100, 10, 8])\n",
      "contexts: torch.Size([100, 10, 8])\n",
      "contexts: torch.Size([100, 10, 8])\n",
      "contexts: torch.Size([100, 10, 8])\n",
      "contexts: torch.Size([100, 10, 8])\n",
      "contexts: torch.Size([100, 10, 8])\n",
      "contexts: torch.Size([100, 10, 8])\n",
      "contexts: torch.Size([100, 10, 8])\n",
      "contexts: torch.Size([100, 10, 8])\n",
      "contexts: torch.Size([100, 10, 8])\n",
      "[Run 0, Task 1, Epoch 1] [Validate] Accuracy :   1.0\n",
      "[Run 0, Task 1, Epoch 1] [Test] Accuracy :   1.0\n",
      "[Task 2, Epoch 0] [Training] loss :  348.75491, acc :   0.0, batch_idx : 0\n",
      "[Task 2, Epoch 0] [Training] loss :  189.80748, acc :  0.1562, batch_idx : 20\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"babi_main.py\", line 283, in <module>\n",
      "    loss, acc = model.get_loss(contexts, questions, answers)\n",
      "  File \"babi_main.py\", line 239, in get_loss\n",
      "    output = self.forward(contexts, questions)\n",
      "  File \"babi_main.py\", line 216, in forward\n",
      "    M = self.memory(facts, questions, M)\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"babi_main.py\", line 127, in forward\n",
      "    C = self.AGRU(facts, G)\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"babi_main.py\", line 75, in forward\n",
      "    C = self.AGRUCell(fact, C, g)\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"babi_main.py\", line 48, in forward\n",
      "    r = F.sigmoid(self.Wr(fact) + self.Ur(C))\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/torch/nn/modules/linear.py\", line 55, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\", line 992, in linear\n",
      "    return torch.addmm(bias, input, weight.t())\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0,1 python babi_main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Background processes not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-c55ad5cc77ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# !nohup python test.py > log.txt &\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nohup CUDA_VISIBLE_DEVICES=0,1 python babi_main.py > log.txt &'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36msystem_piped\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m   2218\u001b[0m             \u001b[0;31m# os.system() or use ip.system=ip.system_raw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2219\u001b[0m             \u001b[0;31m# if they really want a background process.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2220\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Background processes not supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2222\u001b[0m         \u001b[0;31m# we explicitly do NOT return the subprocess status code, because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Background processes not supported."
     ]
    }
   ],
   "source": [
    "# !nohup python test.py > log.txt &\n",
    "!nohup CUDA_VISIBLE_DEVICES=0,1 python babi_main.py > log.txt &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总用量 7444\r\n",
      "-rw-rw-r--  1 hadoop hadoop   26795 6月  13 13:56 10.Dynamic-Memory-Network-for-Question-Answering.ipynb\r\n",
      "-rw-rw-r--  1 hadoop hadoop    5721 7月   4 16:48 babi_loader.py\r\n",
      "-rw-rw-r--  1 hadoop hadoop   14616 7月   4 16:50 babi_main.py\r\n",
      "-rw-rw-r--  1 hadoop hadoop   32436 6月  26 18:03 chinese.py\r\n",
      "drwxrwxr-x 11 hadoop hadoop     324 6月  26 17:45 data\r\n",
      "-rw-rw-r--  1 hadoop hadoop     228 6月  13 11:04 fetch_data.sh\r\n",
      "-rw-rw-r--  1 hadoop hadoop   18490 7月  16 13:48 gpu_condition.ipynb\r\n",
      "-rw-rw-r--  1 hadoop hadoop 3786935 6月  26 18:03 gpu_run.ipynb\r\n",
      "-rw-rw-r--  1 hadoop hadoop 3683982 7月   5 16:20 log.txt\r\n",
      "drwxrwxr-x  2 hadoop hadoop   16384 7月   5 16:20 models\r\n",
      "drwxrwxr-x  2 hadoop hadoop    4096 6月  13 11:08 pretrained_models\r\n",
      "drwxrwxr-x  2 hadoop hadoop      48 7月   4 16:50 __pycache__\r\n",
      "-rw-rw-r--  1 hadoop hadoop    1839 6月  13 11:04 README.md\r\n",
      "-rw-rw-r--  1 hadoop hadoop     154 6月  13 11:04 test.py\r\n",
      "drwxrwxr-x  8 hadoop hadoop    4096 7月  16 13:51 treelstm_dmn\r\n"
     ]
    }
   ],
   "source": [
    "! ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo chmod 666 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
